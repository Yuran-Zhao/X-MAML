You can manully download the multilingual pre-trained models provided by [huggingface](https://huggingface.co/models), and place them in this folder like:
```
+-- cache_dir
|   +-- xlm-roberta-base
|   |   +-- config.json
|   |   +-- pytorch_model.bin
|   |   +-- sentencepiece.bpe.model
|   |   +-- tokenizer.json
|   +-- bert-base-multilingual-uncased
|   |   +-- config.json
|   |   +-- pytorch_model.bin
|   |   +-- tokenizer.json
|   |   +-- tokenizer_config.json
|   |   +-- vocab.txt
|   +-- bert-base-multilingual-cased
|   |   +-- config.json
|   |   +-- pytorch_model.bin
|   |   +-- tokenizer.json
|   |   +-- tokenizer_config.json
|   |   +-- vocab.txt
```